{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "05db90c8-a261-49ec-a4a2-c97cb8013ec7",
      "metadata": {},
      "source": [
        "# Numba\n",
        "\n",
        "[Numba](https://numba.pydata.org/) 是一个开源的 JIT 编译器，能够将 Python 和 NumPy 代码的子集转换为快速的机器码。\n",
        "\n",
        "Numba 通过直接将受限的 Python 代码子集编译为 CUDA 内核和设备函数来支持 CUDA GPU 编程，遵循 CUDA 执行模型。用 Numba 编写的内核似乎可以直接访问 NumPy 数组。NumPy 数组会在 CPU 和 GPU 之间自动传输。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1df11e1b-234c-4008-bf0c-bbdb897e0f07",
      "metadata": {},
      "source": [
        "## 什么是内核？\n",
        "\n",
        "内核类似于函数，它是一个代码块，接受一些输入并由处理器执行。\n",
        "\n",
        "函数和内核之间的区别是：\n",
        "- 内核不能返回任何内容，必须修改内存\n",
        "- 内核必须指定其线程层次结构（线程和块）"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412bb30f-31d3-41b5-bec7-9d7dd72472fc",
      "metadata": {},
      "source": [
        "## 什么是网格、线程和块（以及线程束）？\n",
        "\n",
        "[线程和块](https://en.wikipedia.org/wiki/Thread_block_(CUDA_programming)) 是你指示 GPU 并行处理某些代码的方式。我们的 GPU 是一个并行处理器，所以我们需要指定希望内核执行的次数。\n",
        "\n",
        "线程的好处是它们之间有一些共享的缓存内存，但每个 GPU 上的核心数量有限，所以我们需要将工作分解成块，这些块将在 GPU 上并行调度和运行。\n",
        "\n",
        "<figure>\n",
        "\n",
        "![CPU GPU 对比](images/threads-blocks-warps.png)\n",
        "\n",
        "<figcaption style=\"text-align: center;\"> \n",
        "    \n",
        "图片来源 <a href=\"https://docs.nvidia.com/cuda/cuda-c-programming-guide/\">https://docs.nvidia.com/cuda/cuda-c-programming-guide/</a>\n",
        "    \n",
        "</figcaption>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad6a21f-ce9c-49a2-9b6a-41fbd29bf6d1",
      "metadata": {},
      "source": [
        "### 什么？？\n",
        "\n",
        "现在不要太担心这个。只需要记住**我们需要指定希望内核被调用的次数**，这是通过两个数字相乘来给出整体网格大小的。\n",
        "\n",
        "选择每个块的线程数的经验法则：\n",
        "- 应该是线程束大小（32）的倍数\n",
        "- 一个好的起点是每个块 128-512 个线程，但需要通过基准测试来确定最佳值。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d36336db-8514-4b21-8072-62f085779f93",
      "metadata": {},
      "source": [
        "## Hello world"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8dded05-6f39-4ea3-8ac6-45247ebc35d1",
      "metadata": {},
      "source": [
        "让我们通过一些代码深入了解，希望事情会变得更清晰。\n",
        "\n",
        "首先，让我们编写一个简单的基于 CPU 的 Python 函数，我们将在[列表推导式](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)中重复调用它。从 Python 的角度来看，列表推导式可以是并行计算的一个很好的起点，因为它们本身已经感觉有些并行性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a31223-019a-403b-bbd9-c3daa2f1042f",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = range(10)\n",
        "\n",
        "def foo(i):\n",
        "    return i\n",
        "    \n",
        "[foo(i) for i in data]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c420044-2d0a-4ca6-8643-82f96390ff2a",
      "metadata": {},
      "source": [
        "这里我们的 `foo` 函数返回其索引值，并使用 `for` 循环遍历由 `range` 生成的数据。\n",
        "\n",
        "接下来，我们将把它转换为 CUDA 内核，并使用 Numba CUDA 在我们的 GPU 上运行它。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a1d262-f928-4473-b6b1-450bcb9fe60b",
      "metadata": {},
      "source": [
        "首先我们需要记住，我们的内核不能返回任何内容。相反，我们将使用一个输出列表来存储我们想要返回的值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8d3d9c-72fe-4ff7-b9f9-44e23dcf258e",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = range(10)\n",
        "output = []\n",
        "\n",
        "def foo(i):\n",
        "    output.append(i)\n",
        "    \n",
        "[foo(i) for i in data]\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d161843-ee8d-4cb0-bf02-481c61b8b4e0",
      "metadata": {},
      "source": [
        "我们的下一个挑战是 GPU 上的输出数组必须具有固定长度。我们不能从一个空数组开始并不断追加内容。所以让我们使用 NumPy 创建一个与输入数据长度相同的数组。我们还将输入列表转换为 NumPy 数组，因为这是我们可以移动到 GPU 的内容。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "099b300d-0f4d-4f05-bbc7-b6b0e888f226",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d6832e81-5a23-4af2-bdd1-c562a21e6d33",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = np.asarray(range(10))\n",
        "output = np.zeros(len(data))\n",
        "\n",
        "def foo(i):\n",
        "    output[i] = i\n",
        "    \n",
        "[foo(i) for i in data]\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a42ff5-cc99-4889-acc5-443819664fdd",
      "metadata": {},
      "source": [
        "现在我们的纯 Python 函数行为类似于内核，让我们使用 Numba 将其转换为真正的内核。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "16577800",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['NUMBA_CUDA_USE_NVIDIA_BINDING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e60e9835-253f-4786-be3a-780f08df89da",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/nvidia/lib/python3.11/site-packages/numba/core/config.py:168: UserWarning: CUDA Python bindings requested (the environment variable NUMBA_CUDA_USE_NVIDIA_BINDING is set), but they are not importable: No module named 'cuda'.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda\n",
        "from numba import config as numba_config\n",
        "numba_config.CUDA_ENABLE_PYNVJITLINK = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "edd640a5-ceaf-4fc1-9d87-9f9bda5d1d87",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/nvidia/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/opt/miniconda3/envs/nvidia/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:887: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = np.asarray(range(10))\n",
        "output = np.zeros(len(data))\n",
        "\n",
        "@cuda.jit\n",
        "def foo(input_array, output_array):\n",
        "    i = cuda.grid(1)\n",
        "    output_array[i] = input_array[i]\n",
        "    \n",
        "foo[1, len(data)](data, output)\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758f7db8-9673-4b04-a7b3-2b8ef0e21907",
      "metadata": {},
      "source": [
        "**太棒了，上面的代码在我们的 GPU 上运行了！**\n",
        "\n",
        "现在让我们来解析一下。\n",
        "\n",
        "要将我们的 CPU 函数转换为 GPU 内核，我们需要添加 `@cuda.jit` 装饰器。这告诉 Numba 在运行时将我们的代码编译为 CUDA 兼容的字节码。\n",
        "\n",
        "接下来，我们将内核的输入更改为 `input_array` 和 `output_array`。这是因为我们的内核需要引用这两个数组才能与它们交互。（稍后会详细介绍。）\n",
        "\n",
        "但是 `i` 呢？我们不再需要在每次调用函数时传递索引，而是可以依赖一个很好的 CUDA 函数 `cuda.grid`，它允许我们的内核在运行时获取自己的线程索引。\n",
        "\n",
        "最后我们做了一个看起来奇怪的函数调用 `foo[blocks, threads](input, output)`。为了在 GPU 上并行运行我们的内核，我们需要指定希望它运行的次数。内核函数使用方括号配置，传递块大小和线程大小。由于我们的数组只有 `10` 个元素长，我们指定块大小为 `1`，线程大小为 `10`，这意味着我们的内核将被执行 `10` 次。然后我们像往常一样传递参数。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d83f9b-c4c7-4b18-b83f-21c85cb0a5de",
      "metadata": {},
      "source": [
        "## 稍微大一点的东西\n",
        "\n",
        "现在我们已经用 Numba 运行了第一个 CUDA 内核，让我们尝试一些稍微大一点的东西。\n",
        "\n",
        "这次我们将取一个大型数组，并将其中的每个数字加倍。我们首先在 CPU 上用纯 Python 实现，然后在 GPU 上用 CUDA 内核实现。\n",
        "\n",
        "让我们从一个包含 3000 万个随机数的大型数组开始，以及一个等长的输出数组。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0d06dc1c-b36e-48df-9c7f-0bf109c1ceae",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.13775829, 0.29662486, 0.05549038, ..., 0.66162091, 0.31389995,\n",
              "       0.74693903], shape=(30000000,))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_array = np.random.random((30_000_000))\n",
        "random_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2791c50f-a80b-4ccc-86a1-5955c508dc78",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], shape=(30000000,))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = np.zeros_like(random_array)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d90ac1c-932a-4345-9e70-8a2e24f15c10",
      "metadata": {},
      "source": [
        "然后在 Python 中，让我们遍历这个数组，并将每个项加倍到输出数组中。我们可以计时这个单元格，看看需要多长时间。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "195b97db-2efc-4e64-8f95-3ade92c52a07",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 7.24 s, sys: 134 ms, total: 7.37 s\n",
            "Wall time: 7.37 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.27551658, 0.59324973, 0.11098076, ..., 1.32324181, 0.6277999 ,\n",
              "       1.49387806], shape=(30000000,))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "def foo(i):\n",
        "    output[i] = random_array[i] * 2\n",
        "    \n",
        "[foo(i) for i in range(len(random_array))]\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d881d061-b924-48b5-97d9-8ce5bc862e69",
      "metadata": {},
      "source": [
        "对我来说，CPU 完成这个计算大约需要 10 秒。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966920e3-653d-458c-9f9b-1e740e1db024",
      "metadata": {},
      "source": [
        "接下来，让我们编写一个 CUDA 内核，做完全相同的事情。与上一个示例的唯一区别是，我们将线程大小设置为固定值 `128`，然后计算需要多少个块来覆盖整个数组。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c98f0967-ad98-420f-9ccb-1eae9e242bc7",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9723dc8a-9627-442f-becc-3d9fc5423096",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/nvidia/lib/python3.11/site-packages/numba/cuda/cudadrv/devicearray.py:887: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 281 ms, sys: 54.1 ms, total: 335 ms\n",
            "Wall time: 334 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.27551658, 0.59324973, 0.11098076, ..., 1.32324181, 0.6277999 ,\n",
              "       1.49387806], shape=(30000000,))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "output = np.zeros_like(random_array)\n",
        "\n",
        "threads = 128\n",
        "blocks = math.ceil(random_array.shape[0] / threads)\n",
        "\n",
        "@cuda.jit\n",
        "def foo(input_array, output_array):\n",
        "    i = cuda.grid(1)\n",
        "    output_array[i] = input_array[i] * 2\n",
        "    \n",
        "foo[blocks, threads](random_array, output)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abec8daa-6d42-46cb-b95e-9f896de3a69d",
      "metadata": {},
      "source": [
        "太棒了！现在速度快了几个数量级，只需要几百毫秒。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4043550-55eb-4a74-bdb7-32e97f58314e",
      "metadata": {},
      "source": [
        "精明的你可能会想，NumPy 已经是一个基于 C 的优化库，我们正在将 GPU 内核与一些纯 Python 代码进行比较。如果我们用 NumPy 实现会怎样？\n",
        "\n",
        "嗯，你是对的，在这个例子中，NumPy 仍然比我们的 GPU 快。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ac1d6108-8d8f-4318-b7d8-f08cbf5c8b4d",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 31 ms, sys: 48.2 ms, total: 79.1 ms\n",
            "Wall time: 77.7 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.27551658, 0.59324973, 0.11098076, ..., 1.32324181, 0.6277999 ,\n",
              "       1.49387806], shape=(30000000,))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "random_array * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b5a9d0e-775a-4871-8416-f81e232e728e",
      "metadata": {},
      "source": [
        "但这种情况的原因是内存管理。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "383ba959-6e68-4f89-a887-8c139e847789",
      "metadata": {},
      "source": [
        "## 内存管理\n",
        "\n",
        "之前我们讨论过，CPU 和 GPU 实际上是两台独立的计算机。每台计算机都有自己的内存。\n",
        "\n",
        "到目前为止我们处理的所有数据都是在 CPU 上用 `numpy` 创建的。因此，为了让 `numba` 在 GPU 上处理这些数据，它一直在悄悄地为我们来回复制数据。\n",
        "\n",
        "这种数据移动会带来性能损失。\n",
        "\n",
        "我们也可以选择自己控制数据。我们可以使用 `cuda.to_device` 提前将数组显式移动到 GPU。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a96de9eb-2adc-4179-89ce-5be1bdc2fb6b",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "gpu_random_array = cuda.to_device(random_array)\n",
        "gpu_output = cuda.to_device(np.zeros_like(random_array))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8dccdba5-b280-448e-9d26-98e0120b283d",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7fb5884ee990>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_random_array"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d552a86-08da-4324-bfc4-1c726aca528d",
      "metadata": {},
      "source": [
        "现在如果我们再次运行内核，并将 GPU 内存数组传递给它，我们会看到它确实比 NumPy 表现更好。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "651b7b29-4bad-4015-af25-1040f15b1946",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 ms ± 20.2 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 100\n",
        "foo[blocks, threads](gpu_random_array, gpu_output)\n",
        "cuda.synchronize()  # 等待内核计算，因为它会延迟完成"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39df78d6-6ea7-4252-9bcd-203d0920a81b",
      "metadata": {},
      "source": [
        "然而我们的输出结果也仍然在 GPU 上。我们显式地将其复制到了那里，所以我们需要使用 `copy_to_host()` 显式地将其复制回来。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6d1d93c1-f54d-4c4f-a789-237ff74409d9",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.27551658, 0.59324973, 0.11098076, ..., 1.32324181, 0.6277999 ,\n",
              "       1.49387806], shape=(30000000,))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_output.copy_to_host()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dc8ac8-433c-46e0-a978-065364089e18",
      "metadata": {},
      "source": [
        "这两种数据移动操作都需要时间。但我们在这里执行的计算是微不足道的。随着内核内的计算变得越来越复杂，复制数据所花费的时间比例会变得越来越小。\n",
        "\n",
        "内存管理在其他地方也很有用。我们可能希望编写代码，在其中编写许多内核并将它们链接在一起。在每个内核调用之间将数据复制到 GPU 并再次复制回来将是低效的。\n",
        "\n",
        "```python\n",
        "# 将数组移动到 GPU\n",
        "foo[blocks, threads](data, output)\n",
        "# 将数据移回 CPU\n",
        "\n",
        "# 将数组移动到 GPU\n",
        "bar[blocks, threads](data, output)\n",
        "# 将数据移回 CPU\n",
        "\n",
        "# 将数组移动到 GPU\n",
        "baz[blocks, threads](data, output)\n",
        "# 将数据移回 CPU\n",
        "```\n",
        "\n",
        "因此，通过显式地将数据放在那里，我们可以减少这个时间，并更好地控制我们的计算。\n",
        "\n",
        "```python\n",
        "# 将数组移动到 GPU\n",
        "data = cuda.to_device(data)\n",
        "output = cuda.to_device(output)\n",
        "\n",
        "foo[blocks, threads](data, output)\n",
        "bar[blocks, threads](data, output)\n",
        "baz[blocks, threads](data, output)\n",
        "\n",
        "# 将数据移回 CPU\n",
        "data = data.copy_to_host()\n",
        "output = output.copy_to_host()\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "nvidia",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
