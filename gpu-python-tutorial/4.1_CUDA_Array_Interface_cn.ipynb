{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "65312eb9-ddbc-4c05-9857-1ac431bd8e66",
      "metadata": {},
      "source": [
        "# CUDA 数组接口\n",
        "\n",
        "由于将数据从CPU移动到GPU的开销很大，我们希望尽可能多地保持数据始终位于GPU上。\n",
        "\n",
        "有时在我们的工作流程中，我们也想改变使用的工具。也许我们使用`cupy`加载了一个数据数组，但我们想用`numba`编写一个自定义的CUDA内核。或者我们想切换到使用像`pytorch`这样的深度学习框架。\n",
        "\n",
        "当这些库中的任何一个将数据加载到GPU上时，内存中的数组基本上是相同的。cupy的`ndarray`和numba的`DeviceNDArray`之间的区别仅在于数组如何被包装并连接到Python。\n",
        "\n",
        "幸运的是，借助像[DLPack](https://github.com/dmlc/dlpack)和[`__cuda_array__interface__`](https://numba.readthedocs.io/en/stable/cuda/cuda_array_interface.html)这样的实用工具，我们可以在不修改GPU上数据的情况下从一种类型转换为另一种类型。我们只需创建一个新的Python包装器对象并传输所有设备指针。\n",
        "\n",
        "确保流行的GPU Python库之间的兼容性是RAPIDS社区的核心目标之一。\n",
        "\n",
        "![](images/array-interface.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a072fd72-44bd-4371-95b6-e853da8d7cb6",
      "metadata": {},
      "source": [
        "让我们看看这个功能的实际应用！"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e991c2ac-4cbd-4e3c-9b1e-22f8338876dc",
      "metadata": {},
      "source": [
        "我们首先使用CuPy创建一个数组。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a9dbc32-409c-45bd-8d4d-a5662030ec87",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0.17572606, 0.38152158, 0.64269351, ..., 0.07515534,\n",
              "         0.99049298, 0.94435744],\n",
              "        [0.26558308, 0.79105898, 0.5082067 , ..., 0.88454661,\n",
              "         0.28137788, 0.37358692],\n",
              "        [0.38617845, 0.76164433, 0.17188144, ..., 0.34715918,\n",
              "         0.38098977, 0.30668737],\n",
              "        ...,\n",
              "        [0.60317778, 0.69273163, 0.39666527, ..., 0.51775052,\n",
              "         0.37331455, 0.59810914],\n",
              "        [0.4196741 , 0.9361488 , 0.21997834, ..., 0.29165336,\n",
              "         0.24868757, 0.8217988 ],\n",
              "        [0.15465472, 0.37924016, 0.50648938, ..., 0.76492635,\n",
              "         0.22148569, 0.47322672]],\n",
              "\n",
              "       [[0.43089097, 0.87470549, 0.07045724, ..., 0.1061153 ,\n",
              "         0.75396014, 0.40997852],\n",
              "        [0.91328209, 0.18884004, 0.83711646, ..., 0.09092838,\n",
              "         0.14908714, 0.94945127],\n",
              "        [0.64622264, 0.75736539, 0.69856194, ..., 0.01780518,\n",
              "         0.49111054, 0.61353111],\n",
              "        ...,\n",
              "        [0.69348589, 0.63368185, 0.57559398, ..., 0.79274069,\n",
              "         0.85933448, 0.81995581],\n",
              "        [0.50221249, 0.15896956, 0.58303   , ..., 0.80997639,\n",
              "         0.75169475, 0.985234  ],\n",
              "        [0.11315831, 0.50808019, 0.54077763, ..., 0.56516712,\n",
              "         0.32551777, 0.95393269]],\n",
              "\n",
              "       [[0.29525559, 0.83982192, 0.64062837, ..., 0.57657505,\n",
              "         0.97251644, 0.25913403],\n",
              "        [0.72413843, 0.16051078, 0.87793867, ..., 0.16914792,\n",
              "         0.11380692, 0.93345551],\n",
              "        [0.59136862, 0.63765931, 0.31220147, ..., 0.05118147,\n",
              "         0.93401073, 0.66164226],\n",
              "        ...,\n",
              "        [0.98537296, 0.58369604, 0.25208146, ..., 0.47967981,\n",
              "         0.21835982, 0.39509368],\n",
              "        [0.65383294, 0.7305273 , 0.79247889, ..., 0.66033645,\n",
              "         0.25982937, 0.55749404],\n",
              "        [0.31167298, 0.27515397, 0.88521496, ..., 0.02138252,\n",
              "         0.92320492, 0.44727138]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.36133133, 0.08058428, 0.72204277, ..., 0.19227199,\n",
              "         0.75859706, 0.18541414],\n",
              "        [0.4557256 , 0.63413457, 0.05313626, ..., 0.56669831,\n",
              "         0.71197843, 0.00671278],\n",
              "        [0.50926372, 0.49273819, 0.11654621, ..., 0.95697197,\n",
              "         0.50281333, 0.25962996],\n",
              "        ...,\n",
              "        [0.3927123 , 0.52308431, 0.59732042, ..., 0.0924571 ,\n",
              "         0.75428205, 0.36354502],\n",
              "        [0.45667239, 0.38139376, 0.33448433, ..., 0.10695446,\n",
              "         0.20143863, 0.67689222],\n",
              "        [0.38692078, 0.43795183, 0.29119725, ..., 0.90679435,\n",
              "         0.5108079 , 0.83954215]],\n",
              "\n",
              "       [[0.83075712, 0.96637072, 0.39047731, ..., 0.54991498,\n",
              "         0.91383348, 0.85185532],\n",
              "        [0.1292989 , 0.16699453, 0.4212497 , ..., 0.76517671,\n",
              "         0.86604352, 0.394992  ],\n",
              "        [0.19024734, 0.51950058, 0.96001879, ..., 0.57897301,\n",
              "         0.36529379, 0.86757932],\n",
              "        ...,\n",
              "        [0.37284588, 0.61919846, 0.97121861, ..., 0.58769446,\n",
              "         0.55376277, 0.88362804],\n",
              "        [0.13244007, 0.51954516, 0.90017003, ..., 0.77404309,\n",
              "         0.45566374, 0.53508706],\n",
              "        [0.31256156, 0.42964067, 0.77693135, ..., 0.27403894,\n",
              "         0.41703497, 0.82291315]],\n",
              "\n",
              "       [[0.4443704 , 0.97793494, 0.92283035, ..., 0.71373873,\n",
              "         0.25007575, 0.54356993],\n",
              "        [0.44044132, 0.63763737, 0.93022097, ..., 0.82114544,\n",
              "         0.6629235 , 0.35801574],\n",
              "        [0.82665816, 0.36506807, 0.95959026, ..., 0.71998466,\n",
              "         0.60020637, 0.55236323],\n",
              "        ...,\n",
              "        [0.90254733, 0.77069334, 0.11794419, ..., 0.01103196,\n",
              "         0.85425358, 0.23004445],\n",
              "        [0.73201706, 0.1819021 , 0.37841144, ..., 0.74766522,\n",
              "         0.72020054, 0.52024467],\n",
              "        [0.67695441, 0.36551303, 0.86885142, ..., 0.38641137,\n",
              "         0.16905233, 0.74183238]]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cupy as cp\n",
        "# 使用更合理的数组大小以避免内存问题\n",
        "cp_arr = cp.random.random((100, 1000, 1000))\n",
        "cp_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0f132109-0042-417e-8b21-7ad73cc3aa52",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cupy.ndarray"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(cp_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2de53d-0d7f-4b3b-9859-f08520ed8bb7",
      "metadata": {},
      "source": [
        "现在让我们将其转换为Numba数组。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "191859ce-56c1-480f-ad6c-d76051c08c53",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f16a89dd190>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from numba import cuda\n",
        "from numba import config as numba_config\n",
        "numba_config.CUDA_ENABLE_PYNVJITLINK = True\n",
        "\n",
        "numba_arr = cuda.to_device(cp_arr)\n",
        "numba_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18613c12-d419-4bc5-9bf0-15c07818e536",
      "metadata": {},
      "source": [
        "_请注意GPU内存使用量保持不变。这是因为`cp_arr`和`numba_arr`都引用相同的基础数据数组，但属于不同的类型。_\n",
        "\n",
        "我们也可以将数组转换为PyTorch的`Tensor`对象。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "37dd98ce-1ff2-4fde-bd62-865d6a042a54",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch CUDA已初始化\n",
            "CUDA设备: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch  # Requires pytorch\n",
        "\n",
        "# 在Jupyter Notebook中，需要先初始化PyTorch的CUDA上下文\n",
        "# 这样可以避免后续使用CUDA数组接口时出现初始化错误\n",
        "torch.cuda.init()\n",
        "print(f'PyTorch CUDA已初始化')\n",
        "print(f'CUDA设备: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "04d891c3-7499-4a37-a064-bf6f73c174ff",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.1757, 0.3815, 0.6427,  ..., 0.0752, 0.9905, 0.9444],\n",
              "         [0.2656, 0.7911, 0.5082,  ..., 0.8845, 0.2814, 0.3736],\n",
              "         [0.3862, 0.7616, 0.1719,  ..., 0.3472, 0.3810, 0.3067],\n",
              "         ...,\n",
              "         [0.6032, 0.6927, 0.3967,  ..., 0.5178, 0.3733, 0.5981],\n",
              "         [0.4197, 0.9361, 0.2200,  ..., 0.2917, 0.2487, 0.8218],\n",
              "         [0.1547, 0.3792, 0.5065,  ..., 0.7649, 0.2215, 0.4732]],\n",
              "\n",
              "        [[0.4309, 0.8747, 0.0705,  ..., 0.1061, 0.7540, 0.4100],\n",
              "         [0.9133, 0.1888, 0.8371,  ..., 0.0909, 0.1491, 0.9495],\n",
              "         [0.6462, 0.7574, 0.6986,  ..., 0.0178, 0.4911, 0.6135],\n",
              "         ...,\n",
              "         [0.6935, 0.6337, 0.5756,  ..., 0.7927, 0.8593, 0.8200],\n",
              "         [0.5022, 0.1590, 0.5830,  ..., 0.8100, 0.7517, 0.9852],\n",
              "         [0.1132, 0.5081, 0.5408,  ..., 0.5652, 0.3255, 0.9539]],\n",
              "\n",
              "        [[0.2953, 0.8398, 0.6406,  ..., 0.5766, 0.9725, 0.2591],\n",
              "         [0.7241, 0.1605, 0.8779,  ..., 0.1691, 0.1138, 0.9335],\n",
              "         [0.5914, 0.6377, 0.3122,  ..., 0.0512, 0.9340, 0.6616],\n",
              "         ...,\n",
              "         [0.9854, 0.5837, 0.2521,  ..., 0.4797, 0.2184, 0.3951],\n",
              "         [0.6538, 0.7305, 0.7925,  ..., 0.6603, 0.2598, 0.5575],\n",
              "         [0.3117, 0.2752, 0.8852,  ..., 0.0214, 0.9232, 0.4473]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.3613, 0.0806, 0.7220,  ..., 0.1923, 0.7586, 0.1854],\n",
              "         [0.4557, 0.6341, 0.0531,  ..., 0.5667, 0.7120, 0.0067],\n",
              "         [0.5093, 0.4927, 0.1165,  ..., 0.9570, 0.5028, 0.2596],\n",
              "         ...,\n",
              "         [0.3927, 0.5231, 0.5973,  ..., 0.0925, 0.7543, 0.3635],\n",
              "         [0.4567, 0.3814, 0.3345,  ..., 0.1070, 0.2014, 0.6769],\n",
              "         [0.3869, 0.4380, 0.2912,  ..., 0.9068, 0.5108, 0.8395]],\n",
              "\n",
              "        [[0.8308, 0.9664, 0.3905,  ..., 0.5499, 0.9138, 0.8519],\n",
              "         [0.1293, 0.1670, 0.4212,  ..., 0.7652, 0.8660, 0.3950],\n",
              "         [0.1902, 0.5195, 0.9600,  ..., 0.5790, 0.3653, 0.8676],\n",
              "         ...,\n",
              "         [0.3728, 0.6192, 0.9712,  ..., 0.5877, 0.5538, 0.8836],\n",
              "         [0.1324, 0.5195, 0.9002,  ..., 0.7740, 0.4557, 0.5351],\n",
              "         [0.3126, 0.4296, 0.7769,  ..., 0.2740, 0.4170, 0.8229]],\n",
              "\n",
              "        [[0.4444, 0.9779, 0.9228,  ..., 0.7137, 0.2501, 0.5436],\n",
              "         [0.4404, 0.6376, 0.9302,  ..., 0.8211, 0.6629, 0.3580],\n",
              "         [0.8267, 0.3651, 0.9596,  ..., 0.7200, 0.6002, 0.5524],\n",
              "         ...,\n",
              "         [0.9025, 0.7707, 0.1179,  ..., 0.0110, 0.8543, 0.2300],\n",
              "         [0.7320, 0.1819, 0.3784,  ..., 0.7477, 0.7202, 0.5202],\n",
              "         [0.6770, 0.3655, 0.8689,  ..., 0.3864, 0.1691, 0.7418]]],\n",
              "       device='cuda:0', dtype=torch.float64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 方法1：直接转换Numba数组到PyTorch（推荐）\n",
        "torch_arr = torch.as_tensor(numba_arr, device='cuda')\n",
        "torch_arr\n",
        "\n",
        "# 方法2：如果直接转换失败，可以通过CuPy中转\n",
        "# cp_from_numba = cp.asarray(numba_arr)\n",
        "# torch_arr = torch.as_tensor(cp_from_numba, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4fc1495d-04c1-4746-9242-a05795586ecc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(torch_arr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "nvidia",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
