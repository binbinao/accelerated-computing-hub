{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0d57565e-f93f-4878-bebc-deb6ca2fc195",
      "metadata": {},
      "source": [
        "# CuPy 与 nvmath-python\n",
        "\n",
        "## 环境要求\n",
        "\n",
        "在运行本笔记本之前，请确保已正确配置环境：\n",
        "\n",
        "### 1. 安装必要的包\n",
        "\n",
        "```bash\n",
        "# 使用 conda 安装（推荐）\n",
        "conda install -c conda-forge -c rapidsai nvmath-python-dx \"pynvjitlink>=0.2\" cuda-version=12 -y\n",
        "\n",
        "# 或使用 pip 安装\n",
        "pip install nvmath-python\n",
        "```\n",
        "\n",
        "### 2. 确保兼容的版本\n",
        "\n",
        "```bash\n",
        "# nvmath-python 需要特定版本的依赖\n",
        "pip install \"numba==0.58.1\" \"numpy==1.26.4\" --force-reinstall\n",
        "```\n",
        "\n",
        "### 3. 设置 CUDA_HOME 环境变量\n",
        "\n",
        "在 Jupyter Notebook 中运行以下代码：\n",
        "\n",
        "```python\n",
        "import os\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda-12.4'  # 根据你的 CUDA 安装路径调整\n",
        "```\n",
        "\n",
        "### 4. 重启 Jupyter 内核\n",
        "\n",
        "安装完成后，请重启 Jupyter 内核（Kernel → Restart Kernel）。\n",
        "\n",
        "### 故障排除\n",
        "\n",
        "如果遇到 `ImportError: cannot import name 'make_attribute_wrapper'` 错误：\n",
        "- 确保 numba 版本为 0.58.1 或更早版本\n",
        "- 确保 numpy 版本为 1.26.4 或更早版本\n",
        "\n",
        "如果遇到 `RuntimeError: cudart headers not found` 错误：\n",
        "- 设置 CUDA_HOME 环境变量指向你的 CUDA Toolkit 安装路径\n",
        "\n",
        "---\n",
        "\n",
        "**nvmath-python**（Beta）库将 NVIDIA 数学库的强大功能带入 Python 生态系统。该软件包旨在提供直观的 Python 风格 API，让用户能够在各种执行空间中完全访问 NVIDIA 库提供的所有功能。nvmath-python 与现有的 Python 数组/张量框架无缝协作，专注于提供这些框架所缺少的功能。\n",
        "\n",
        "该库旨在满足以下需求：\n",
        "- 研究人员寻求生产力、与其他库和框架的互操作性以及性能\n",
        "- 库/框架开发人员寻求开箱即用的性能和通过 Python 实现更好的可维护性\n",
        "- 内核开发人员寻求最高性能而无需切换到 CUDA\n",
        "\n",
        "Nvmath-python 特性：\n",
        "- CUDA 数学库的低级绑定\n",
        "- Python 风格的高级 API（主机和设备）：目前仅限于扩展的矩阵乘法和 FFT\n",
        "- 可在 Numba 内核中调用的设备函数\n",
        "- 与 NumPy、CuPy 和 PyTorch 张量的互操作性\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd3e83b-0db7-4bd1-8335-549870987066",
      "metadata": {},
      "source": [
        "## 入门指南\n",
        "\n",
        "1. 原型设计\n",
        "\n",
        "```python\n",
        "# 在第一个版本中使用 CPU 上的 NumPy 数组\n",
        "import numpy as np\n",
        "import nvmath\n",
        "\n",
        "# 驻留在 CPU 上的 NumPy 数组：\n",
        "a = np.random.rand(128, 1024, 1024)\n",
        "\n",
        "# 执行空间是 CPU（默认）：\n",
        "r = nvmath.fft.fft(a) \n",
        "```\n",
        "\n",
        "注意：nvmath-python 不仅可以在 GPU 上运行，还通过 NVPL（aarch64）和 MKL（x86）支持 CPU 执行空间\n",
        "\n",
        "2. 将原型迁移到 GPU\n",
        "\n",
        "```python\n",
        "# 使用 CuPy 数组迁移到 GPU\n",
        "import cupy as cp\n",
        "import nvmath\n",
        "\n",
        "# 驻留在 GPU 上的 CuPy 数组：\n",
        "a = cp.random.rand(128, 1024, 1024)\n",
        "\n",
        "# 执行空间是 GPU：\n",
        "r = nvmath.fft.fft(a) \n",
        "```\n",
        "\n",
        "注意：nvmath-python 与现有的张量库（numpy、cupy、pytorch）互操作，可以轻松集成到现有的 CPU 和 GPU 工作流程中\n",
        "\n",
        "3. 扩展\n",
        "\n",
        "```python\n",
        "# 使用 nvmath.distributed 扩展到多 GPU\n",
        "import numpy as np\n",
        "import nvmath\n",
        "\n",
        "# 驻留在 CPU 上的 NumPy 本地数组\n",
        "a = np.random.rand(128, 1024, 1024)\n",
        "\n",
        "# 分布式结果作为本地数组\n",
        "r = nvmath.distributed.fft.fft(a)\n",
        "```\n",
        "注意：nvmath-python 可以在峰值库性能下扩展到单个 GPU 之外\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54de48ee-abd0-4c2d-b58b-ebebf3db4f86",
      "metadata": {},
      "source": [
        "# 高级模块\n",
        "提供常见的开箱即用的高性能操作，无需离开 Python。\n",
        "\n",
        "这包括：\n",
        "- 线性代数\n",
        "- 快速傅里叶变换\n",
        "\n",
        "nvmath-python 库支持融合尾声操作，提供增强的性能。可用的尾声操作包括：\n",
        "- RELU：应用修正线性单元激活函数。\n",
        "- GELU：应用高斯误差线性单元激活函数。\n",
        "- BIAS：添加偏置向量。\n",
        "- SIGMOID：应用 sigmoid 函数。\n",
        "- TANH：应用双曲正切函数。\n",
        "这些尾声可以组合使用，例如，RELU 和 BIAS 可以融合。自定义尾声也可以定义为 Python 函数并使用 LTO-IR 编译。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5baa815-4f85-480a-9db0-9f075cf3c4e2",
      "metadata": {},
      "source": [
        "## 线性代数\n",
        "\n",
        "nvmath-python 库提供了一个专门的矩阵乘法接口，可以将缩放的矩阵-矩阵乘法与预定义的尾声操作作为单个融合内核执行。这种内核融合可能会显著提高效率。\n",
        "\n",
        "此外，nvmath-python 的有状态 API 将此类操作分解为规划、自动调优和执行阶段，这使得可以在多次执行中分摊一次性准备成本。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b0d9ed9-c17c-40a1-858b-6ff02612b83c",
      "metadata": {},
      "source": [
        "### 使用 CuPy 数组的矩阵乘法（无状态）\n",
        "\n",
        "此示例演示了 CuPy 数组的基本矩阵乘法。\n",
        "\n",
        "nvmath-python 支持多个框架。每个操作的结果都是与用于传递输入的框架相同的张量。\n",
        "它也位于与输入相同的设备上。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "562dcc68-0fcb-4aa5-b4c1-3f9d566e91ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs were of types <class 'cupy.ndarray'> and <class 'cupy.ndarray'> and the result is of type <class 'cupy.ndarray'>.\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "import nvmath\n",
        "\n",
        "# Prepare sample input data.\n",
        "n, m, k = 123, 456, 789\n",
        "a = cp.random.rand(n, k)\n",
        "b = cp.random.rand(k, m)\n",
        "\n",
        "# Perform the multiplication.\n",
        "result = nvmath.linalg.advanced.matmul(a, b)\n",
        "\n",
        "# Synchronize the default stream, since by default the execution is non-blocking for GPU\n",
        "# operands.\n",
        "cp.cuda.get_current_stream().synchronize()\n",
        "\n",
        "# Check if the result is cupy array as well.\n",
        "print(f\"Inputs were of types {type(a)} and {type(b)} and the result is of type {type(result)}.\")\n",
        "assert isinstance(result, cp.ndarray)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07484302-fa3f-463a-bc5f-7b9eb4e7e74c",
      "metadata": {},
      "source": [
        "### 使用 CuPy 数组的矩阵乘法（有状态）\n",
        "\n",
        "此示例说明了有状态矩阵乘法对象的使用。有状态对象可以在多次执行中分摊准备成本。\n",
        "\n",
        "输入和结果都是 CuPy ndarray。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4042bbe9-77d9-4350-944f-23441c090c77",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input types = (<class 'cupy.ndarray'>, <class 'cupy.ndarray'>), device = (<CUDA Device 0>, <CUDA Device 0>)\n",
            "Result type = <class 'cupy.ndarray'>, device = <CUDA Device 0>\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "import nvmath\n",
        "\n",
        "# Prepare sample input data.\n",
        "m, n, k = 123, 456, 789\n",
        "a = cp.random.rand(m, k)\n",
        "b = cp.random.rand(k, n)\n",
        "\n",
        "# Use the stateful object as a context manager to automatically release resources.\n",
        "with nvmath.linalg.advanced.Matmul(a, b) as mm:\n",
        "    # Plan the matrix multiplication. Planning returns a sequence of algorithms that can be\n",
        "    # configured as we'll see in a later example.\n",
        "    mm.plan()\n",
        "\n",
        "    # Execute the matrix multiplication.\n",
        "    result = mm.execute()\n",
        "\n",
        "    # Synchronize the default stream, since by default the execution is non-blocking for GPU\n",
        "    # operands.\n",
        "    cp.cuda.get_current_stream().synchronize()\n",
        "    print(f\"Input types = {type(a), type(b)}, device = {a.device, b.device}\")\n",
        "    print(f\"Result type = {type(result)}, device = {result.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26dccc23-0964-41b9-850c-d09f49994b4a",
      "metadata": {},
      "source": [
        "### 使用 CuPy 数组的矩阵乘法（带尾声的无状态）\n",
        "\n",
        "此示例演示了尾声的使用。\n",
        "\n",
        "尾声允许您在单个融合内核中的矩阵乘法之后执行额外的计算。\n",
        "在此示例中，我们将使用 BIAS 尾声，它将偏置添加到结果中。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a944484-ad57-4ecd-b19c-fce4eba796ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs were of types <class 'cupy.ndarray'> and <class 'cupy.ndarray'>, the bias type is <class 'cupy.ndarray'>, and the result is of type <class 'cupy.ndarray'>.\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "import nvmath\n",
        "\n",
        "# Prepare sample input data.\n",
        "m, n, k = 64, 128, 256\n",
        "a = cp.random.rand(m, k)\n",
        "b = cp.random.rand(k, n)\n",
        "bias = cp.random.rand(m, 1)\n",
        "\n",
        "# Perform the multiplication with BIAS epilog.\n",
        "epilog = nvmath.linalg.advanced.MatmulEpilog.BIAS\n",
        "result = nvmath.linalg.advanced.matmul(a, b, epilog=epilog, epilog_inputs={\"bias\": bias})\n",
        "\n",
        "# Synchronize the default stream, since by default the execution is non-blocking for GPU\n",
        "# operands.\n",
        "cp.cuda.get_current_stream().synchronize()\n",
        "print(f\"Inputs were of types {type(a)} and {type(b)}, the bias type is {type(bias)}, and the result is of type {type(result)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98fdf970-d3d6-4df4-b7b6-29db4b1c6d45",
      "metadata": {},
      "source": [
        "## 快速傅里叶变换\n",
        "\n",
        "在 NVIDIA cuFFT 库的支持下，nvmath-python 提供了一组强大的 API 来执行 N 维离散傅里叶变换。这些包括复数到复数、复数到实数和实数到复数情况的正向和逆向变换。这些操作以各种精度提供，既有主机 API 也有设备 API。\n",
        "\n",
        "用户可以为选定的 nvmath-python 操作（如 FFT）提供用 Python 编写的回调函数，这会产生融合内核，并可能显著提高性能。高级用户可以从 nvmath-python 设备 API 中受益，该 API 可以将 FFT 和矩阵乘法等核心数学操作融合到单个内核中，使性能接近理论最大值。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04168852-8ed0-445a-ad71-7e9783680ab8",
      "metadata": {},
      "source": [
        "### 使用 CuPy 数组的 FFT\n",
        "\n",
        "FFT 操作的输入和结果都是 CuPy ndarray，\n",
        "从而实现 nvmath-python 和 CuPy 之间的轻松互操作。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a47200ee-42f5-4aec-ae98-af9b202aff1a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input type = <class 'cupy.ndarray'>, device = <CUDA Device 0>\n",
            "FFT output type = <class 'cupy.ndarray'>, device = <CUDA Device 0>\n",
            "IFFT output type = <class 'cupy.ndarray'>, device = <CUDA Device 0>\n"
          ]
        }
      ],
      "source": [
        "import cupy as cp\n",
        "import nvmath\n",
        "\n",
        "shape = 512, 256, 512\n",
        "axes = 0, 1\n",
        "\n",
        "a = cp.random.rand(*shape, dtype=cp.float64) + 1j * cp.random.rand(*shape, dtype=cp.float64)\n",
        "\n",
        "# Forward FFT along the specified axes, batched along the complement.\n",
        "b = nvmath.fft.fft(a, axes=axes)\n",
        "\n",
        "# Inverse FFT along the specified axes, batched along the complement.\n",
        "c = nvmath.fft.ifft(b, axes=axes)\n",
        "\n",
        "# Synchronize the default stream\n",
        "cp.cuda.get_current_stream().synchronize()\n",
        "print(f\"Input type = {type(a)}, device = {a.device}\")\n",
        "print(f\"FFT output type = {type(b)}, device = {b.device}\")\n",
        "print(f\"IFFT output type = {type(c)}, device = {c.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de89f2b-e29b-4aea-b6d6-4eb127a67559",
      "metadata": {},
      "source": [
        "### 带回调的 FFT\n",
        "\n",
        "用户定义的函数可以编译为 LTO-IR 格式，并作为 FFT 操作的尾声或序言提供，从而允许链接时优化和融合。\n",
        "\n",
        "此示例展示了如何通过将 Python 回调函数作为 IFFT 操作的序言来执行卷积。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26268251-a738-412a-9201-8bbf0c2dc672",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "import nvmath\n",
        "\n",
        "# Create the data for the batched 1-D FFT.\n",
        "B, N = 256, 1024\n",
        "a = cp.random.rand(B, N, dtype=cp.float64) + 1j * cp.random.rand(B, N, dtype=cp.float64)\n",
        "\n",
        "# Create the data to use as filter.\n",
        "filter_data = cp.sin(a)\n",
        "\n",
        "# Define the prolog function for the inverse FFT.\n",
        "# A convolution corresponds to pointwise multiplication in the frequency domain.\n",
        "def convolve(data_in, offset, filter_data, unused):\n",
        "    # Note we are accessing `data_out` and `filter_data` with a single `offset` integer,\n",
        "    # even though the input and `filter_data` are 2D tensors (batches of samples).\n",
        "    # Care must be taken to assure that both arrays accessed here have the same memory\n",
        "    # layout.\n",
        "    return data_in[offset] * filter_data[offset] / N\n",
        "\n",
        "# Compile the prolog to LTO-IR.\n",
        "with cp.cuda.Device():\n",
        "    prolog = nvmath.fft.compile_prolog(convolve, \"complex128\", \"complex128\")\n",
        "\n",
        "# Perform the forward FFT, followed by the inverse FFT, applying the filter as a prolog.\n",
        "r = nvmath.fft.fft(a, axes=[-1])\n",
        "r = nvmath.fft.ifft(r, axes=[-1], prolog={\n",
        "        \"ltoir\": prolog,\n",
        "        \"data\": filter_data.data.ptr\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2edda3e0-bb7c-4e5f-b3be-4f8d3d9f8f77",
      "metadata": {},
      "source": [
        "# 低级模块\n",
        "提供对 CUDA 内部和 CUDA C 数学库的直接访问。\n",
        "\n",
        "这包括：\n",
        "- 设备 API\n",
        "- 数学库绑定\n",
        "\n",
        "还可以访问主机 API（以及带回调的主机 API），但我们将在这里重点关注设备端。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ac6216-22d2-4aa0-bc77-52d28d36d208",
      "metadata": {},
      "source": [
        "## 设备 API\n",
        "\n",
        "nvmath-python 的设备模块 `nvmath.device` 通过 cuFFTDx、cuBLASDx 和 cuRAND 的设备 API 提供与 NVIDIA 高性能计算库的集成。这些库的详细文档可以分别在 [cuFFTDx](https://docs.nvidia.com/cuda/cufftdx/1.2.0/)、[cuBLASDx](https://docs.nvidia.com/cuda/cublasdx/0.1.1/) 和 [cuRAND](https://docs.nvidia.com/cuda/curand/group__DEVICE.html#group__DEVICE) 设备 API 中找到。\n",
        "\n",
        "用户可以通过以下两种方法利用设备模块：\n",
        "- Numba 扩展：用户可以通过 Numba 访问这些设备 API，利用特定的扩展来简化定义函数、查询设备特性和调用设备函数的过程。\n",
        "- 第三方 JIT 编译器：这些 API 也可以通过其他 JIT 编译器中的低级接口使用，允许高级用户直接使用原始设备代码。\n",
        "\n",
        "\n",
        "此示例展示了如何使用 cuRAND 从正态分布中采样单精度值。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15d32e3-02ed-4caa-ace2-581111832487",
      "metadata": {},
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "from numba import config as numba_config\n",
        "numba_config.CUDA_ENABLE_PYNVJITLINK = True\n",
        "\n",
        "from nvmath.device import random\n",
        "compiled_apis = random.Compile()\n",
        "\n",
        "threads, blocks = 64, 64\n",
        "nthreads = blocks * threads\n",
        "\n",
        "states = random.StatesPhilox4_32_10(nthreads)\n",
        "\n",
        "# Next, define and launch a setup kernel, which will initialize the states using\n",
        "# nvmath.device.random.init function.\n",
        "@cuda.jit(link=compiled_apis.files, extensions=compiled_apis.extension)\n",
        "def setup(states):\n",
        "    i = cuda.grid(1)\n",
        "    random.init(1234, i, 0, states[i])\n",
        "\n",
        "setup[blocks, threads](states)\n",
        "\n",
        "# With your states array ready, you can use samplers such as\n",
        "# nvmath.device.random.normal2 to sample random values in your kernels.\n",
        "@cuda.jit(link=compiled_apis.files, extensions=compiled_apis.extension)\n",
        "def kernel(states):\n",
        "    i = cuda.grid(1)\n",
        "    random_values = random.normal2(states[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e15297-aeda-4eff-8b48-f66dbfd119b8",
      "metadata": {},
      "source": [
        "## 数学库绑定\n",
        "\n",
        "NVIDIA 数学库的 C API 的低级 Python 绑定在 nvmath.bindings 中的相应模块下公开。要访问 Python 绑定，请使用相应库的模块。在底层，nvmath-python 会为您延迟处理到库的运行时链接。\n",
        "\n",
        "当前支持的库及其相应的模块名称如下：\n",
        "- [cuBLAS](https://docs.nvidia.com/cuda/cublas/) (`nvmath.bindings.cublas`)\n",
        "- [cuBLASLt](https://docs.nvidia.com/cuda/cublas/#using-the-cublaslt-api) (`nvmath.bindings.cublasLt`)\n",
        "- [cuFFT](https://docs.nvidia.com/cuda/cufft/) (`nvmath.bindings.cufft`)\n",
        "- [cuRAND](https://docs.nvidia.com/cuda/curand/index.html) (`nvmath.bindings.curand`)\n",
        "- [cuSOLVER](https://docs.nvidia.com/cuda/cusolver/index.html) (`nvmath.bindings.cusolver`)\n",
        "- [cuSOLVERDn](https://docs.nvidia.com/cuda/cusolver/index.html#cusolverdn-dense-lapack) (`nvmath.bindings.cusolverDn`)\n",
        "- [cuSPARSE](https://docs.nvidia.com/cuda/cusparse/) (`nvmath.bindings.cusparse`)\n",
        "\n",
        "将库函数名称从 C 转换为 Python 的指南记录在此处：https://docs.nvidia.com/cuda/nvmath-python/latest/bindings/index.html "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267ada4e-10a5-4bf1-9935-ba085dc77028",
      "metadata": {},
      "source": [
        "## 参考链接\n",
        "nvmath-python 主页：https://developer.nvidia.com/nvmath-python \n",
        "\n",
        "nvmath-python 文档：https://docs.nvidia.com/cuda/nvmath-python/latest/index.html \n",
        "\n",
        "nvmath-python GitHub 仓库：https://developer.nvidia.com/nvmath-python\n",
        "\n",
        "使用 nvmath-python 将尾声操作与矩阵乘法融合的博客文章：https://developer.nvidia.com/blog/fusing-epilog-operations-with-matrix-multiplication-using-nvmath-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b74393-0393-4d24-be0e-d510b4f23c02",
      "metadata": {},
      "source": [
        "# 示例\n",
        "\n",
        "完整的示例集可在 nvmath-python Github 仓库中找到：https://github.com/NVIDIA/nvmath-python/tree/main/examples "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "nvidia",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
